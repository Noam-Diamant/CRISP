{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SAE Feature Intervention Experiment\n",
        "\n",
        "This notebook implements feature interventions using TransformerLens and SAE features identified in the basketball/baseball analysis. We modify activations at layer 16 to suppress basketball features and amplify baseball features, then evaluate the impact on token predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Fix Dependencies (if needed)\n",
        "\n",
        "If you encounter a scipy/numpy compatibility error when importing TransformerLens, run the cell below to fix it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upgrading scipy and numpy to fix compatibility issues...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Dependencies upgraded successfully!\n",
            "\n",
            "================================================================================\n",
            "IMPORTANT: You must restart the kernel for changes to take effect!\n",
            "================================================================================\n",
            "\n",
            "Steps:\n",
            "1. Go to: Kernel → Restart Kernel (or press Ctrl+M, then 0, then 0)\n",
            "2. After restart, run all cells from the beginning\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Run this cell if you get scipy/numpy import errors\n",
        "# This will upgrade scipy and numpy to compatible versions\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Upgrading scipy and numpy to fix compatibility issues...\")\n",
        "try:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"scipy>=1.11.0\", \"numpy>=1.24.0\"], \n",
        "                         stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    print(\"✓ Dependencies upgraded successfully!\")\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"IMPORTANT: You must restart the kernel for changes to take effect!\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nSteps:\")\n",
        "    print(\"1. Go to: Kernel → Restart Kernel (or press Ctrl+M, then 0, then 0)\")\n",
        "    print(\"2. After restart, run all cells from the beginning\")\n",
        "    print(\"=\"*80)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error upgrading dependencies: {e}\")\n",
        "    print(\"\\nTry running this command manually in your terminal:\")\n",
        "    print(\"  pip install --upgrade 'scipy>=1.11.0' 'numpy>=1.24.0'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/dsi/fetaya-lab/noam_diamant/conda/envs/crisp_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Successfully imported HookedTransformer\n",
            "Using model: meta-llama/Llama-3.1-8B\n",
            "Operating on layer: 16\n",
            "Basketball intervention factor: -5.0\n",
            "Baseball intervention factor: 5.0\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "from typing import Set, Dict, List, Tuple\n",
        "from dataclasses import dataclass\n",
        "from IPython.display import HTML, display\n",
        "import pandas as pd\n",
        "\n",
        "# Workaround for scipy/numpy compatibility issue\n",
        "# This patches the scipy issue before importing transformer_lens\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# Try to patch the scipy issue if it exists\n",
        "try:\n",
        "    import scipy.special._multiufuncs\n",
        "    # The issue is in MultiUFunc initialization - try to bypass it\n",
        "    # by ensuring numpy is properly initialized first\n",
        "    _ = np.array([1, 2, 3])  # Force numpy initialization\n",
        "except Exception as scipy_init_err:\n",
        "    # If scipy fails to initialize, we'll handle it below\n",
        "    pass\n",
        "\n",
        "# Import TransformerLens with error handling\n",
        "try:\n",
        "    from transformer_lens import HookedTransformer\n",
        "    print(\"✓ Successfully imported HookedTransformer\")\n",
        "except (ValueError, ImportError) as e:\n",
        "    error_msg = str(e)\n",
        "    if \"numpy.ufunc\" in error_msg or \"scipy\" in error_msg.lower():\n",
        "        print(\"=\"*80)\n",
        "        print(\"DEPENDENCY ISSUE DETECTED: scipy/numpy version incompatibility\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"\\nTo fix this, run one of the following commands in your terminal:\")\n",
        "        print(\"\\n  Option 1 (pip):\")\n",
        "        print(\"    pip install --upgrade 'scipy>=1.11.0' 'numpy>=1.24.0'\")\n",
        "        print(\"\\n  Option 2 (conda):\")\n",
        "        print(\"    conda update scipy numpy\")\n",
        "        print(\"\\n  Option 3 (reinstall compatible versions):\")\n",
        "        print(\"    pip uninstall scipy numpy -y\")\n",
        "        print(\"    pip install 'scipy>=1.11.0' 'numpy>=1.24.0'\")\n",
        "        print(\"\\nAfter fixing, restart your kernel and run this cell again.\")\n",
        "        print(\"=\"*80)\n",
        "        raise ImportError(\n",
        "            \"TransformerLens import failed due to scipy/numpy incompatibility. \"\n",
        "            \"Please fix dependencies as shown above and restart the kernel.\"\n",
        "        ) from e\n",
        "    else:\n",
        "        raise\n",
        "\n",
        "from globals import LLAMA_3_1_8B\n",
        "from crisp import LayerFeatures\n",
        "from sae import TopkSae\n",
        "from utils import load_cached_features\n",
        "from data import prepare_text\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Set GPU device\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"  # Adjust as needed\n",
        "\n",
        "# Configuration from basketball_baseball_analysis.ipynb\n",
        "MODEL_CARD = LLAMA_3_1_8B\n",
        "LAYER_TO_ANALYZE = 16\n",
        "SAE_SAVE_PATH = \"llama_sae_cache\"\n",
        "\n",
        "# Intervention configuration (configurable)\n",
        "INTERVENTION_FACTOR_BASKETBALL = -5.0  # Complete suppression (0.0) or partial (e.g., 0.5)\n",
        "INTERVENTION_FACTOR_BASEBALL = 5.0    # Amplification factor (2.0 = 2x amplification)\n",
        "\n",
        "# Feature threshold (same as used in topk_filtered)\n",
        "FEATURE_THRESHOLD = 3.0\n",
        "\n",
        "print(f\"Using model: {MODEL_CARD}\")\n",
        "print(f\"Operating on layer: {LAYER_TO_ANALYZE}\")\n",
        "print(f\"Basketball intervention factor: {INTERVENTION_FACTOR_BASKETBALL}\")\n",
        "print(f\"Baseball intervention factor: {INTERVENTION_FACTOR_BASEBALL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Cached Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading features from Basketball vs Baseball comparison...\n",
            "Loaded 19122 features for Basketball vs Baseball\n",
            "\n",
            "Found 2000 significant basketball features (target_acts_relative >= 3.0)\n",
            "Found 1819 significant baseball features (benign_acts_relative >= 3.0)\n",
            "Overlap: 0 features\n",
            "\n",
            "Feature source: baseball\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# PARAMETER: Choose feature source\n",
        "# ============================================================================\n",
        "# Options:\n",
        "#   \"wiki\" - Load from basketball vs wiki and baseball vs wiki comparisons\n",
        "#   \"baseball\" - Load from basketball vs baseball comparison\n",
        "# ============================================================================\n",
        "FEATURE_SOURCE = \"baseball\"  # Change to \"baseball\" to use basketball vs baseball comparison\n",
        "\n",
        "# Create data config classes (same as in basketball_baseball_analysis.ipynb)\n",
        "@dataclass\n",
        "class BasketballBaseballDataConfig:\n",
        "    max_length: int = 1000\n",
        "    min_length: int = 100\n",
        "    n_examples: int = 250\n",
        "    data_type: str = \"basketball_baseball\"\n",
        "    forget_type: str = \"basketball\"\n",
        "    retain_type: str = \"wiki\"\n",
        "    \n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"max_length\": self.max_length,\n",
        "            \"min_length\": self.min_length,\n",
        "            \"n_examples\": self.n_examples,\n",
        "            \"data_type\": self.data_type,\n",
        "            \"forget_type\": self.forget_type,\n",
        "            \"retain_type\": self.retain_type\n",
        "        }\n",
        "\n",
        "if FEATURE_SOURCE == \"wiki\":\n",
        "    # Load basketball vs wiki features\n",
        "    print(\"Loading features from Basketball vs Wiki and Baseball vs Wiki comparisons...\")\n",
        "    data_config_basketball_wiki = BasketballBaseballDataConfig(\n",
        "        n_examples=250,\n",
        "        data_type=\"basketball_wiki\",\n",
        "        forget_type=\"basketball\",\n",
        "        retain_type=\"wiki\"\n",
        "    )\n",
        "\n",
        "    basketball_wiki_features = load_cached_features(\n",
        "        LAYER_TO_ANALYZE,\n",
        "        data_config_basketball_wiki,\n",
        "        model_name=MODEL_CARD\n",
        "    )\n",
        "\n",
        "    if basketball_wiki_features is None:\n",
        "        raise ValueError(\"Basketball vs wiki features not found. Please run basketball_baseball_analysis.ipynb first.\")\n",
        "\n",
        "    basketball_layer_features = LayerFeatures(list(basketball_wiki_features))\n",
        "    print(f\"Loaded {len(basketball_layer_features)} features for Basketball vs Wikipedia\")\n",
        "\n",
        "    # Load baseball vs wiki features\n",
        "    data_config_baseball_wiki = BasketballBaseballDataConfig(\n",
        "        n_examples=250,\n",
        "        data_type=\"baseball_wiki\",\n",
        "        forget_type=\"baseball\",\n",
        "        retain_type=\"wiki\"\n",
        "    )\n",
        "\n",
        "    baseball_wiki_features = load_cached_features(\n",
        "        LAYER_TO_ANALYZE,\n",
        "        data_config_baseball_wiki,\n",
        "        model_name=MODEL_CARD\n",
        "    )\n",
        "\n",
        "    if baseball_wiki_features is None:\n",
        "        raise ValueError(\"Baseball vs wiki features not found. Please run basketball_baseball_analysis.ipynb first.\")\n",
        "\n",
        "    baseball_layer_features = LayerFeatures(list(baseball_wiki_features))\n",
        "    print(f\"Loaded {len(baseball_layer_features)} features for Baseball vs Wikipedia\")\n",
        "\n",
        "    # Extract significant feature indices\n",
        "    # Basketball features: high target_acts_relative (basketball vs wiki)\n",
        "    # Baseball features: high benign_acts_relative (baseball vs wiki)\n",
        "    basketball_feature_indices: Set[int] = set()\n",
        "    for feature in basketball_layer_features.features.values():\n",
        "        if feature.target_acts_relative >= FEATURE_THRESHOLD:\n",
        "            basketball_feature_indices.add(feature.index)\n",
        "\n",
        "    baseball_feature_indices: Set[int] = set()\n",
        "    for feature in baseball_layer_features.features.values():\n",
        "        if feature.benign_acts_relative >= FEATURE_THRESHOLD:\n",
        "            baseball_feature_indices.add(feature.index)\n",
        "\n",
        "elif FEATURE_SOURCE == \"baseball\":\n",
        "    # Load basketball vs baseball features\n",
        "    print(\"Loading features from Basketball vs Baseball comparison...\")\n",
        "    data_config_basketball_baseball = BasketballBaseballDataConfig(\n",
        "        n_examples=250,\n",
        "        data_type=\"basketball_baseball\",\n",
        "        forget_type=\"basketball\",\n",
        "        retain_type=\"baseball\"\n",
        "    )\n",
        "\n",
        "    basketball_baseball_features = load_cached_features(\n",
        "        LAYER_TO_ANALYZE,\n",
        "        data_config_basketball_baseball,\n",
        "        model_name=MODEL_CARD\n",
        "    )\n",
        "\n",
        "    if basketball_baseball_features is None:\n",
        "        raise ValueError(\"Basketball vs baseball features not found. Please run basketball_baseball_analysis.ipynb first.\")\n",
        "\n",
        "    basketball_baseball_layer_features = LayerFeatures(list(basketball_baseball_features))\n",
        "    print(f\"Loaded {len(basketball_baseball_layer_features)} features for Basketball vs Baseball\")\n",
        "\n",
        "    # Extract significant feature indices from basketball vs baseball comparison\n",
        "    # Basketball features: high target_acts_relative (basketball is target)\n",
        "    # Baseball features: high benign_acts_relative (baseball is benign/retain)\n",
        "    basketball_feature_indices: Set[int] = set()\n",
        "    for feature in basketball_baseball_layer_features.features.values():\n",
        "        if feature.target_acts_relative >= FEATURE_THRESHOLD:\n",
        "            basketball_feature_indices.add(feature.index)\n",
        "\n",
        "    baseball_feature_indices: Set[int] = set()\n",
        "    for feature in basketball_baseball_layer_features.features.values():\n",
        "        if feature.benign_acts_relative >= FEATURE_THRESHOLD:\n",
        "            baseball_feature_indices.add(feature.index)\n",
        "\n",
        "else:\n",
        "    raise ValueError(f\"Invalid FEATURE_SOURCE: {FEATURE_SOURCE}. Must be 'wiki' or 'baseball'.\")\n",
        "\n",
        "print(f\"\\nFound {len(basketball_feature_indices)} significant basketball features (target_acts_relative >= {FEATURE_THRESHOLD})\")\n",
        "print(f\"Found {len(baseball_feature_indices)} significant baseball features (benign_acts_relative >= {FEATURE_THRESHOLD})\")\n",
        "print(f\"Overlap: {len(basketball_feature_indices & baseball_feature_indices)} features\")\n",
        "print(f\"\\nFeature source: {FEATURE_SOURCE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load SAE and Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading SAE for layer 16...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAE loaded. Input dim: 4096, SAE dim: 32768, Top-k: 50\n",
            "Loading model with TransformerLens...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 106.52it/s]\n",
            "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n",
            "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model meta-llama/Llama-3.1-8B into HookedTransformer\n",
            "Model loaded. Hidden size: 4096\n",
            "✓ Dimensions verified\n"
          ]
        }
      ],
      "source": [
        "# Load SAE for layer 16\n",
        "print(\"Loading SAE for layer 16...\")\n",
        "layer_path = os.path.join(SAE_SAVE_PATH, f\"layer_{LAYER_TO_ANALYZE}\")\n",
        "if not os.path.exists(layer_path):\n",
        "    raise FileNotFoundError(f\"SAE not found at {layer_path}. Please run basketball_baseball_analysis.ipynb first.\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "sae = TopkSae.load_from_disk(layer_path, device=device, decoder=True)\n",
        "print(f\"SAE loaded. Input dim: {sae.d_in}, SAE dim: {sae.d_sae}, Top-k: {sae.cfg.k}\")\n",
        "\n",
        "# Load model using TransformerLens\n",
        "print(\"Loading model with TransformerLens...\")\n",
        "model = HookedTransformer.from_pretrained(\n",
        "    MODEL_CARD,\n",
        "    device=device,\n",
        "    dtype=torch.bfloat16,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "print(f\"Model loaded. Hidden size: {model.cfg.d_model}\")\n",
        "\n",
        "# Verify dimensions match\n",
        "assert sae.d_in == model.cfg.d_model, f\"SAE input dim ({sae.d_in}) doesn't match model hidden size ({model.cfg.d_model})\"\n",
        "print(\"✓ Dimensions verified\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Implement Intervention Hook Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intervention hook created successfully\n"
          ]
        }
      ],
      "source": [
        "def create_intervention_hook(\n",
        "    sae: TopkSae,\n",
        "    basketball_indices: Set[int],\n",
        "    baseball_indices: Set[int],\n",
        "    basketball_factor: float,\n",
        "    baseball_factor: float\n",
        "):\n",
        "    \"\"\"\n",
        "    Create a hook function that modifies hidden states by intervening on SAE features.\n",
        "    \n",
        "    Args:\n",
        "        sae: The SAE model\n",
        "        basketball_indices: Set of basketball feature indices to suppress\n",
        "        baseball_indices: Set of baseball feature indices to amplify\n",
        "        basketball_factor: Multiplier for basketball features (0.0 = suppress, 1.0 = no change)\n",
        "        baseball_factor: Multiplier for baseball features (1.0 = no change, >1.0 = amplify)\n",
        "    \n",
        "    Returns:\n",
        "        Hook function that can be used with TransformerLens\n",
        "    \"\"\"\n",
        "    def intervention_hook(hidden_states, hook):\n",
        "        \"\"\"\n",
        "        Hook function that modifies hidden states at layer 16.\n",
        "        \n",
        "        Args:\n",
        "            hidden_states: Tensor of shape (batch, seq_len, hidden_dim)\n",
        "            hook: TransformerLens hook object\n",
        "        \n",
        "        Returns:\n",
        "            Modified hidden states\n",
        "        \"\"\"\n",
        "        # Convert sets to tensors for efficient vectorized operations (inside hook for device access)\n",
        "        basketball_tensor = torch.tensor(list(basketball_indices), device=hidden_states.device, dtype=torch.long)\n",
        "        baseball_tensor = torch.tensor(list(baseball_indices), device=hidden_states.device, dtype=torch.long)\n",
        "        batch_size, seq_len, hidden_dim = hidden_states.shape\n",
        "        \n",
        "        # Reshape for SAE processing: (batch * seq_len, hidden_dim)\n",
        "        hidden_flat = hidden_states.reshape(-1, hidden_dim)\n",
        "        \n",
        "        # Encode through SAE to get feature activations\n",
        "        # Get pre-activations and select top-k\n",
        "        pre_acts = sae.encode_pre_relu(hidden_flat)  # (batch * seq_len, d_sae)\n",
        "        acts = torch.relu(pre_acts)  # (batch * seq_len, d_sae)\n",
        "        \n",
        "        # Get top-k activations and indices\n",
        "        topk_acts, topk_indices = acts.topk(sae.cfg.k, dim=-1, sorted=False)\n",
        "        # topk_acts: (batch * seq_len, k)\n",
        "        # topk_indices: (batch * seq_len, k)\n",
        "        \n",
        "        # Create intervention mask using vectorized operations\n",
        "        # Shape: (batch * seq_len, k)\n",
        "        batch_seq_len = topk_indices.shape[0]\n",
        "        \n",
        "        # Create masks for basketball and baseball features\n",
        "        # Expand indices for comparison: (batch * seq_len, k, 1) vs (1, len(basketball_indices))\n",
        "        topk_indices_expanded = topk_indices.unsqueeze(-1)  # (batch * seq_len, k, 1)\n",
        "        basketball_mask = (topk_indices_expanded == basketball_tensor.unsqueeze(0).unsqueeze(0)).any(dim=-1)  # (batch * seq_len, k)\n",
        "        baseball_mask = (topk_indices_expanded == baseball_tensor.unsqueeze(0).unsqueeze(0)).any(dim=-1)  # (batch * seq_len, k)\n",
        "        \n",
        "        # Apply intervention factors\n",
        "        intervention_factors = torch.ones_like(topk_acts)\n",
        "        intervention_factors[basketball_mask] = basketball_factor\n",
        "        intervention_factors[baseball_mask] = baseball_factor\n",
        "        \n",
        "        # Apply interventions\n",
        "        modified_topk_acts = topk_acts * intervention_factors\n",
        "        \n",
        "        # Create sparse activation tensor and scatter modified activations\n",
        "        sparse_acts = torch.zeros_like(acts)\n",
        "        sparse_acts.scatter_(-1, topk_indices, modified_topk_acts)\n",
        "        \n",
        "        # Decode modified activations back to hidden state space\n",
        "        modified_hidden_flat = sae.decode(sparse_acts)  # (batch * seq_len, hidden_dim)\n",
        "        \n",
        "        # Reshape back to original shape\n",
        "        modified_hidden = modified_hidden_flat.reshape(batch_size, seq_len, hidden_dim)\n",
        "        \n",
        "        return modified_hidden\n",
        "    \n",
        "    return intervention_hook\n",
        "\n",
        "# Create the intervention hook\n",
        "intervention_hook = create_intervention_hook(\n",
        "    sae=sae,\n",
        "    basketball_indices=basketball_feature_indices,\n",
        "    baseball_indices=baseball_feature_indices,\n",
        "    basketball_factor=INTERVENTION_FACTOR_BASKETBALL,\n",
        "    baseball_factor=INTERVENTION_FACTOR_BASEBALL\n",
        ")\n",
        "\n",
        "print(\"Intervention hook created successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Create Intervention Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Utility functions created\n"
          ]
        }
      ],
      "source": [
        "def get_top_tokens(logits: torch.Tensor, tokenizer, k: int = 5) -> List[Tuple[int, str, float]]:\n",
        "    \"\"\"\n",
        "    Get top k tokens from logits.\n",
        "    \n",
        "    Args:\n",
        "        logits: Tensor of shape (batch, seq_len, vocab_size) or (vocab_size,)\n",
        "        tokenizer: Tokenizer to decode tokens\n",
        "        k: Number of top tokens to return\n",
        "    \n",
        "    Returns:\n",
        "        List of (token_id, token_text, probability) tuples\n",
        "    \"\"\"\n",
        "    # Handle different input shapes\n",
        "    if logits.dim() == 3:\n",
        "        # Take the last token's logits\n",
        "        logits = logits[0, -1, :]\n",
        "    elif logits.dim() == 2:\n",
        "        # Take the last token's logits\n",
        "        logits = logits[0, -1, :]\n",
        "    \n",
        "    # Get probabilities\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    \n",
        "    # Get top k\n",
        "    top_probs, top_indices = probs.topk(k, dim=-1)\n",
        "    \n",
        "    # Decode tokens and return with IDs\n",
        "    results = []\n",
        "    for prob, idx in zip(top_probs, top_indices):\n",
        "        token_id = idx.item()\n",
        "        token_text = tokenizer.decode([token_id])\n",
        "        results.append((token_id, token_text, prob.item()))\n",
        "    \n",
        "    return results\n",
        "\n",
        "def run_model_with_intervention(\n",
        "    model: HookedTransformer,\n",
        "    prompt: str,\n",
        "    intervention_hook,\n",
        "    layer: int\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Run model with intervention hook.\n",
        "    \n",
        "    Args:\n",
        "        model: HookedTransformer model\n",
        "        prompt: Input prompt\n",
        "        intervention_hook: Hook function to apply\n",
        "        layer: Layer to hook into\n",
        "    \n",
        "    Returns:\n",
        "        Logits tensor\n",
        "    \"\"\"\n",
        "    hook_name = f\"blocks.{layer}.hook_resid_post\"\n",
        "    \n",
        "    with model.hooks([(hook_name, intervention_hook)]):\n",
        "        logits = model(prompt, return_type=\"logits\")\n",
        "    \n",
        "    return logits\n",
        "\n",
        "def run_model_without_intervention(\n",
        "    model: HookedTransformer,\n",
        "    prompt: str\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Run model without intervention.\n",
        "    \n",
        "    Args:\n",
        "        model: HookedTransformer model\n",
        "        prompt: Input prompt\n",
        "    \n",
        "    Returns:\n",
        "        Logits tensor\n",
        "    \"\"\"\n",
        "    logits = model(prompt, return_type=\"logits\")\n",
        "    return logits\n",
        "\n",
        "def compare_predictions(\n",
        "    prompt: str,\n",
        "    model: HookedTransformer,\n",
        "    intervention_hook,\n",
        "    layer: int,\n",
        "    k: int = 5\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Compare predictions with and without intervention.\n",
        "    \n",
        "    Args:\n",
        "        prompt: Input prompt\n",
        "        model: HookedTransformer model\n",
        "        intervention_hook: Hook function\n",
        "        layer: Layer to hook into\n",
        "        k: Number of top tokens to return\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with original and modified predictions\n",
        "    \"\"\"\n",
        "    # Run without intervention\n",
        "    logits_original = run_model_without_intervention(model, prompt)\n",
        "    top_original = get_top_tokens(logits_original, model.tokenizer, k)\n",
        "    \n",
        "    # Run with intervention\n",
        "    logits_modified = run_model_with_intervention(model, prompt, intervention_hook, layer)\n",
        "    top_modified = get_top_tokens(logits_modified, model.tokenizer, k)\n",
        "    \n",
        "    return {\n",
        "        \"prompt\": prompt,\n",
        "        \"original\": top_original,\n",
        "        \"modified\": top_modified,\n",
        "        \"logits_original\": logits_original,\n",
        "        \"logits_modified\": logits_modified\n",
        "    }\n",
        "\n",
        "print(\"Utility functions created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Wikipedia sample for prompt 2...\n",
            "Prompt 1: Michael Jordan plays the sports of\n",
            "\n",
            "Prompt 2: As the Nameless officially do not exist , the upper echelons of the Gallian Army exploit the concept of plausible deniability in order to send them on missions that would otherwise make Gallia lose\n"
          ]
        }
      ],
      "source": [
        "# Prompt 1: Michael Jordan prompt\n",
        "prompt1 = \"Michael Jordan plays the sports of\"\n",
        "\n",
        "# Prompt 2: Load a sample from Wikipedia retain examples\n",
        "print(\"Loading Wikipedia sample for prompt 2...\")\n",
        "wiki_data = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\")\n",
        "wiki_texts = prepare_text(wiki_data['text'], max_len=1000)\n",
        "\n",
        "# Take a sample that's not related to sports\n",
        "# Filter for texts that don't contain basketball/baseball keywords\n",
        "sports_keywords = [\"basketball\", \"baseball\", \"sport\", \"game\", \"player\", \"team\", \"coach\"]\n",
        "wiki_samples = [text for text in wiki_texts[:100] \n",
        "                if not any(keyword in text.lower() for keyword in sports_keywords)]\n",
        "\n",
        "if len(wiki_samples) > 0:\n",
        "    prompt2 = wiki_samples[0][:200]  # Take first 200 chars\n",
        "    # Ensure it ends at a word boundary\n",
        "    if len(prompt2) < len(wiki_samples[0]):\n",
        "        last_space = prompt2.rfind(' ')\n",
        "        if last_space > 0:\n",
        "            prompt2 = prompt2[:last_space]\n",
        "else:\n",
        "    # Fallback to a generic prompt\n",
        "    prompt2 = \"The history of science involves many important discoveries and developments.\"\n",
        "\n",
        "print(f\"Prompt 1: {prompt1}\")\n",
        "print(f\"\\nPrompt 2: {prompt2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Run Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "EXPERIMENT 1: Michael Jordan Prompt\n",
            "================================================================================\n",
            "\n",
            "Prompt: Michael Jordan plays the sports of\n",
            "\n",
            "Top 5 tokens WITHOUT intervention:\n",
            "  1. ID: 19794  Text: ' basketball'                  (prob: 0.4590)\n",
            "  2. ID: 19665  Text: ' golf'                        (prob: 0.1689)\n",
            "  3. ID: 813    Text: ' his'                         (prob: 0.1157)\n",
            "  4. ID: 2324   Text: ' life'                        (prob: 0.0189)\n",
            "  5. ID: 279    Text: ' the'                         (prob: 0.0178)\n",
            "  6. ID: 20075  Text: ' baseball'                    (prob: 0.0178)\n",
            "  7. ID: 32515  Text: ' tennis'                      (prob: 0.0167)\n",
            "  8. ID: 47589  Text: ' Basketball'                  (prob: 0.0122)\n",
            "  9. ID: 9141   Text: ' football'                    (prob: 0.0051)\n",
            "  10. ID: 28131  Text: ' Golf'                        (prob: 0.0051)\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'k' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m             token_id = \u001b[33m\"\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken_id\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<6\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(token_text)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<30\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (prob: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprob\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTop \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mk\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tokens WITH intervention:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, token_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results1[\u001b[33m'\u001b[39m\u001b[33mmodified\u001b[39m\u001b[33m'\u001b[39m], \u001b[32m1\u001b[39m):\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Handle both old format (2 values) and new format (3 values)\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(token_data) == \u001b[32m3\u001b[39m:\n",
            "\u001b[31mNameError\u001b[39m: name 'k' is not defined"
          ]
        }
      ],
      "source": [
        "# Run experiment for Prompt 1\n",
        "print(\"=\"*80)\n",
        "print(\"EXPERIMENT 1: Michael Jordan Prompt\")\n",
        "print(\"=\"*80)\n",
        "k = 10\n",
        "results1 = compare_predictions(\n",
        "    prompt1,\n",
        "    model,\n",
        "    intervention_hook,\n",
        "    LAYER_TO_ANALYZE,\n",
        "    k=k\n",
        ")\n",
        "\n",
        "print(f\"\\nPrompt: {results1['prompt']}\")\n",
        "print(\"\\nTop 5 tokens WITHOUT intervention:\")\n",
        "for i, token_data in enumerate(results1['original'], 1):\n",
        "    # Handle both old format (2 values) and new format (3 values)\n",
        "    if len(token_data) == 3:\n",
        "        token_id, token_text, prob = token_data\n",
        "    else:\n",
        "        # Old format - decode token ID from text if possible\n",
        "        token_text, prob = token_data\n",
        "        # Try to get token ID by encoding the text\n",
        "        try:\n",
        "            token_id = model.tokenizer.encode(token_text, add_special_tokens=False)[0]\n",
        "        except:\n",
        "            token_id = \"N/A\"\n",
        "    print(f\"  {i}. ID: {token_id:<6} Text: {repr(token_text):<30} (prob: {prob:.4f})\")\n",
        "\n",
        "print(f\"\\nTop {k} tokens WITH intervention:\")\n",
        "for i, token_data in enumerate(results1['modified'], 1):\n",
        "    # Handle both old format (2 values) and new format (3 values)\n",
        "    if len(token_data) == 3:\n",
        "        token_id, token_text, prob = token_data\n",
        "    else:\n",
        "        # Old format - decode token ID from text if possible\n",
        "        token_text, prob = token_data\n",
        "        # Try to get token ID by encoding the text\n",
        "        try:\n",
        "            token_id = model.tokenizer.encode(token_text, add_special_tokens=False)[0]\n",
        "        except:\n",
        "            token_id = \"N/A\"\n",
        "    print(f\"  {i}. ID: {token_id:<6} Text: {repr(token_text):<30} (prob: {prob:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "EXPERIMENT 2: General Wikipedia Prompt\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prompt: As the Nameless officially do not exist , the upper echelons of the Gallian Army exploit the concept of plausible deniability in order to send them on missions that would otherwise make Gallia lose\n",
            "\n",
            "Top 5 tokens WITHOUT intervention:\n",
            "  1. ID: 3663   Text: ' face'                        (prob: 0.6641)\n",
            "  2. ID: 1202   Text: ' its'                         (prob: 0.0698)\n",
            "  3. ID: 279    Text: ' the'                         (prob: 0.0330)\n",
            "  4. ID: 38769  Text: ' credibility'                 (prob: 0.0200)\n",
            "  5. ID: 6625   Text: ' international'               (prob: 0.0177)\n",
            "\n",
            "Top 5 tokens WITH intervention:\n",
            "  1. ID: 1202   Text: ' its'                         (prob: 0.6133)\n",
            "  2. ID: 304    Text: ' in'                          (prob: 0.0732)\n",
            "  3. ID: 4033   Text: ' official'                    (prob: 0.0270)\n",
            "  4. ID: 477    Text: ' or'                          (prob: 0.0270)\n",
            "  5. ID: 389    Text: ' on'                          (prob: 0.0270)\n"
          ]
        }
      ],
      "source": [
        "# Run experiment for Prompt 2\n",
        "print(\"=\"*80)\n",
        "print(\"EXPERIMENT 2: General Wikipedia Prompt\")\n",
        "print(\"=\"*80)\n",
        "results2 = compare_predictions(\n",
        "    prompt2,\n",
        "    model,\n",
        "    intervention_hook,\n",
        "    LAYER_TO_ANALYZE,\n",
        "    k=5\n",
        ")\n",
        "\n",
        "print(f\"\\nPrompt: {results2['prompt']}\")\n",
        "print(\"\\nTop 5 tokens WITHOUT intervention:\")\n",
        "for i, token_data in enumerate(results2['original'], 1):\n",
        "    # Handle both old format (2 values) and new format (3 values)\n",
        "    if len(token_data) == 3:\n",
        "        token_id, token_text, prob = token_data\n",
        "    else:\n",
        "        # Old format - decode token ID from text if possible\n",
        "        token_text, prob = token_data\n",
        "        # Try to get token ID by encoding the text\n",
        "        try:\n",
        "            token_id = model.tokenizer.encode(token_text, add_special_tokens=False)[0]\n",
        "        except:\n",
        "            token_id = \"N/A\"\n",
        "    print(f\"  {i}. ID: {token_id:<6} Text: {repr(token_text):<30} (prob: {prob:.4f})\")\n",
        "\n",
        "print(\"\\nTop 5 tokens WITH intervention:\")\n",
        "for i, token_data in enumerate(results2['modified'], 1):\n",
        "    # Handle both old format (2 values) and new format (3 values)\n",
        "    if len(token_data) == 3:\n",
        "        token_id, token_text, prob = token_data\n",
        "    else:\n",
        "        # Old format - decode token ID from text if possible\n",
        "        token_text, prob = token_data\n",
        "        # Try to get token ID by encoding the text\n",
        "        try:\n",
        "            token_id = model.tokenizer.encode(token_text, add_special_tokens=False)[0]\n",
        "        except:\n",
        "            token_id = \"N/A\"\n",
        "    print(f\"  {i}. ID: {token_id:<6} Text: {repr(token_text):<30} (prob: {prob:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Analysis and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "COMPARISON TABLE: Michael Jordan Prompt\n",
            "========================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>Original ID</th>\n",
              "      <th>Original Text</th>\n",
              "      <th>Original Prob</th>\n",
              "      <th>Modified ID</th>\n",
              "      <th>Modified Text</th>\n",
              "      <th>Modified Prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>19794</td>\n",
              "      <td>' basketball'</td>\n",
              "      <td>0.4590</td>\n",
              "      <td>10034</td>\n",
              "      <td>' sports'</td>\n",
              "      <td>0.1689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>19665</td>\n",
              "      <td>' golf'</td>\n",
              "      <td>0.1689</td>\n",
              "      <td>9522</td>\n",
              "      <td>'...\\n'</td>\n",
              "      <td>0.1025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>813</td>\n",
              "      <td>' his'</td>\n",
              "      <td>0.1157</td>\n",
              "      <td>9141</td>\n",
              "      <td>' football'</td>\n",
              "      <td>0.0903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2324</td>\n",
              "      <td>' life'</td>\n",
              "      <td>0.0189</td>\n",
              "      <td>19794</td>\n",
              "      <td>' basketball'</td>\n",
              "      <td>0.0703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>279</td>\n",
              "      <td>' the'</td>\n",
              "      <td>0.0178</td>\n",
              "      <td>10775</td>\n",
              "      <td>' sport'</td>\n",
              "      <td>0.0549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>20075</td>\n",
              "      <td>' baseball'</td>\n",
              "      <td>0.0178</td>\n",
              "      <td>198</td>\n",
              "      <td>'\\n'</td>\n",
              "      <td>0.0276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>32515</td>\n",
              "      <td>' tennis'</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>1131</td>\n",
              "      <td>'...'</td>\n",
              "      <td>0.0228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>47589</td>\n",
              "      <td>' Basketball'</td>\n",
              "      <td>0.0122</td>\n",
              "      <td>1847</td>\n",
              "      <td>' game'</td>\n",
              "      <td>0.0201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>9141</td>\n",
              "      <td>' football'</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>1972</td>\n",
              "      <td>' real'</td>\n",
              "      <td>0.0201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>28131</td>\n",
              "      <td>' Golf'</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>279</td>\n",
              "      <td>' the'</td>\n",
              "      <td>0.0178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rank  Original ID  Original Text Original Prob  Modified ID  Modified Text  \\\n",
              "0     1        19794  ' basketball'        0.4590        10034      ' sports'   \n",
              "1     2        19665        ' golf'        0.1689         9522        '...\\n'   \n",
              "2     3          813         ' his'        0.1157         9141    ' football'   \n",
              "3     4         2324        ' life'        0.0189        19794  ' basketball'   \n",
              "4     5          279         ' the'        0.0178        10775       ' sport'   \n",
              "5     6        20075    ' baseball'        0.0178          198           '\\n'   \n",
              "6     7        32515      ' tennis'        0.0167         1131          '...'   \n",
              "7     8        47589  ' Basketball'        0.0122         1847        ' game'   \n",
              "8     9         9141    ' football'        0.0051         1972        ' real'   \n",
              "9    10        28131        ' Golf'        0.0051          279         ' the'   \n",
              "\n",
              "  Modified Prob  \n",
              "0        0.1689  \n",
              "1        0.1025  \n",
              "2        0.0903  \n",
              "3        0.0703  \n",
              "4        0.0549  \n",
              "5        0.0276  \n",
              "6        0.0228  \n",
              "7        0.0201  \n",
              "8        0.0201  \n",
              "9        0.0178  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Changes:\n",
            "  ID 19794 (' basketball'): Rank 1 → 4 (+3), Prob 0.4590 → 0.0703 (-0.3887)\n",
            "  ID 19665 (' golf'): Dropped from top 5 (was rank 2)\n",
            "  ID 813 (' his'): Dropped from top 5 (was rank 3)\n",
            "  ID 2324 (' life'): Dropped from top 5 (was rank 4)\n",
            "  ID 279 (' the'): Rank 5 → 10 (+5), Prob 0.0178 → 0.0178 (+0.0000)\n",
            "  ID 20075 (' baseball'): Dropped from top 5 (was rank 6)\n",
            "  ID 32515 (' tennis'): Dropped from top 5 (was rank 7)\n",
            "  ID 47589 (' Basketball'): Dropped from top 5 (was rank 8)\n",
            "  ID 9141 (' football'): Rank 9 → 3 (-6), Prob 0.0051 → 0.0903 (+0.0852)\n",
            "  ID 28131 (' Golf'): Dropped from top 5 (was rank 10)\n",
            "  ID 10034 (' sports'): New entry at rank 1 (prob: 0.1689)\n",
            "  ID 9522 ('...\\n'): New entry at rank 2 (prob: 0.1025)\n",
            "  ID 10775 (' sport'): New entry at rank 5 (prob: 0.0549)\n",
            "  ID 198 ('\\n'): New entry at rank 6 (prob: 0.0276)\n",
            "  ID 1131 ('...'): New entry at rank 7 (prob: 0.0228)\n",
            "  ID 1847 (' game'): New entry at rank 8 (prob: 0.0201)\n",
            "  ID 1972 (' real'): New entry at rank 9 (prob: 0.0201)\n",
            "\n",
            "COMPARISON TABLE: General Wikipedia Prompt\n",
            "========================================================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>Original ID</th>\n",
              "      <th>Original Text</th>\n",
              "      <th>Original Prob</th>\n",
              "      <th>Modified ID</th>\n",
              "      <th>Modified Text</th>\n",
              "      <th>Modified Prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3663</td>\n",
              "      <td>' face'</td>\n",
              "      <td>0.6641</td>\n",
              "      <td>1202</td>\n",
              "      <td>' its'</td>\n",
              "      <td>0.6133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1202</td>\n",
              "      <td>' its'</td>\n",
              "      <td>0.0698</td>\n",
              "      <td>304</td>\n",
              "      <td>' in'</td>\n",
              "      <td>0.0732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>279</td>\n",
              "      <td>' the'</td>\n",
              "      <td>0.0330</td>\n",
              "      <td>4033</td>\n",
              "      <td>' official'</td>\n",
              "      <td>0.0270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>38769</td>\n",
              "      <td>' credibility'</td>\n",
              "      <td>0.0200</td>\n",
              "      <td>477</td>\n",
              "      <td>' or'</td>\n",
              "      <td>0.0270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>6625</td>\n",
              "      <td>' international'</td>\n",
              "      <td>0.0177</td>\n",
              "      <td>389</td>\n",
              "      <td>' on'</td>\n",
              "      <td>0.0270</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rank  Original ID     Original Text Original Prob  Modified ID  \\\n",
              "0     1         3663           ' face'        0.6641         1202   \n",
              "1     2         1202            ' its'        0.0698          304   \n",
              "2     3          279            ' the'        0.0330         4033   \n",
              "3     4        38769    ' credibility'        0.0200          477   \n",
              "4     5         6625  ' international'        0.0177          389   \n",
              "\n",
              "  Modified Text Modified Prob  \n",
              "0        ' its'        0.6133  \n",
              "1         ' in'        0.0732  \n",
              "2   ' official'        0.0270  \n",
              "3         ' or'        0.0270  \n",
              "4         ' on'        0.0270  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Changes:\n",
            "  ID 3663 (' face'): Dropped from top 5 (was rank 1)\n",
            "  ID 1202 (' its'): Rank 2 → 1 (-1), Prob 0.0698 → 0.6133 (+0.5435)\n",
            "  ID 279 (' the'): Dropped from top 5 (was rank 3)\n",
            "  ID 38769 (' credibility'): Dropped from top 5 (was rank 4)\n",
            "  ID 6625 (' international'): Dropped from top 5 (was rank 5)\n",
            "  ID 304 (' in'): New entry at rank 2 (prob: 0.0732)\n",
            "  ID 4033 (' official'): New entry at rank 3 (prob: 0.0270)\n",
            "  ID 477 (' or'): New entry at rank 4 (prob: 0.0270)\n",
            "  ID 389 (' on'): New entry at rank 5 (prob: 0.0270)\n"
          ]
        }
      ],
      "source": [
        "# Create comparison tables\n",
        "def create_comparison_table(results: Dict, title: str, tokenizer):\n",
        "    \"\"\"Create a formatted comparison table.\"\"\"\n",
        "    # Normalize data format - handle both old (2-tuple) and new (3-tuple) formats\n",
        "    def normalize_token_data(token_data):\n",
        "        if len(token_data) == 3:\n",
        "            return token_data  # (token_id, token_text, prob)\n",
        "        else:\n",
        "            # Old format: (token_text, prob) - need to get token_id\n",
        "            token_text, prob = token_data\n",
        "            try:\n",
        "                token_id = tokenizer.encode(token_text, add_special_tokens=False)[0]\n",
        "            except:\n",
        "                token_id = \"N/A\"\n",
        "            return (token_id, token_text, prob)\n",
        "    \n",
        "    original_normalized = [normalize_token_data(t) for t in results['original']]\n",
        "    modified_normalized = [normalize_token_data(t) for t in results['modified']]\n",
        "    \n",
        "    df_data = {\n",
        "        \"Rank\": list(range(1, len(original_normalized) + 1)),\n",
        "        \"Original ID\": [t[0] for t in original_normalized],\n",
        "        \"Original Text\": [repr(t[1]) for t in original_normalized],\n",
        "        \"Original Prob\": [f\"{t[2]:.4f}\" for t in original_normalized],\n",
        "        \"Modified ID\": [t[0] for t in modified_normalized],\n",
        "        \"Modified Text\": [repr(t[1]) for t in modified_normalized],\n",
        "        \"Modified Prob\": [f\"{t[2]:.4f}\" for t in modified_normalized],\n",
        "    }\n",
        "    \n",
        "    df = pd.DataFrame(df_data)\n",
        "    \n",
        "    print(f\"\\n{title}\")\n",
        "    print(\"=\"*120)\n",
        "    display(df)\n",
        "    \n",
        "    # Calculate changes\n",
        "    print(\"\\nChanges:\")\n",
        "    original_tokens = {(t[0], repr(t[1])): (i, t[2]) for i, t in enumerate(original_normalized)}\n",
        "    modified_tokens = {(t[0], repr(t[1])): (i, t[2]) for i, t in enumerate(modified_normalized)}\n",
        "    \n",
        "    # Find tokens that changed rank (by token ID)\n",
        "    for (token_id, token_text), (orig_rank, orig_prob) in original_tokens.items():\n",
        "        if (token_id, token_text) in modified_tokens:\n",
        "            mod_rank, mod_prob = modified_tokens[(token_id, token_text)]\n",
        "            if orig_rank != mod_rank:\n",
        "                rank_change = mod_rank - orig_rank\n",
        "                prob_change = mod_prob - orig_prob\n",
        "                print(f\"  ID {token_id} ({token_text}): Rank {orig_rank+1} → {mod_rank+1} ({rank_change:+d}), Prob {orig_prob:.4f} → {mod_prob:.4f} ({prob_change:+.4f})\")\n",
        "        else:\n",
        "            print(f\"  ID {token_id} ({token_text}): Dropped from top 5 (was rank {orig_rank+1})\")\n",
        "    \n",
        "    # Find new tokens\n",
        "    for (token_id, token_text), (mod_rank, mod_prob) in modified_tokens.items():\n",
        "        if (token_id, token_text) not in original_tokens:\n",
        "            print(f\"  ID {token_id} ({token_text}): New entry at rank {mod_rank+1} (prob: {mod_prob:.4f})\")\n",
        "\n",
        "# Create tables for both experiments\n",
        "create_comparison_table(results1, \"COMPARISON TABLE: Michael Jordan Prompt\", model.tokenizer)\n",
        "create_comparison_table(results2, \"COMPARISON TABLE: General Wikipedia Prompt\", model.tokenizer)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "crisp_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
