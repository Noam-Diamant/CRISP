{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b177104",
   "metadata": {},
   "source": [
    "# CRISP: Unlearning Harry Potter Demo\n",
    "\n",
    "This notebook demonstrates the CRISP method for unlearning concept (Harry Potter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c6b121",
   "metadata": {},
   "source": [
    "## 1. Setup and Model Loading\n",
    "We initialize the environment, select the model (Gemma 2 2B or Llama 3.1 8B), and download the necessary Sparse Autoencoders (SAEs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c785c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from globals import GEMMA_2_2B, LLAMA_3_1_8B\n",
    "from crisp import CRISP, CRISPConfig\n",
    "from unlearn import unlearn_lora, UnlearnConfig\n",
    "from data import load_hp_data, HPDataConfig, genenrate_hp_eval_text\n",
    "from sae import JumpReLUSAE, TopkSae\n",
    "from eval import get_mcq_accuracy\n",
    "from utils import load_cached_features, get_feature_tokens\n",
    "from crisp import LayerFeatures\n",
    "from plot import plot_features_scatter\n",
    "\n",
    "# os.environ['HF_TOKEN'] = <YOUR_HF_TOKEN>\n",
    "if os.environ['HF_TOKEN'] is None:\n",
    "    raise ValueError(\"HF_TOKEN environment variable not set. Please set it to your Hugging Face token.\")\n",
    "\n",
    "# Configuration\n",
    "MODEL_CARD = GEMMA_2_2B # LLAMA_3_1_8B\n",
    "is_gemma = (MODEL_CARD == GEMMA_2_2B)\n",
    "\n",
    "GEMMA_CONFIG = {\n",
    "    \"sae_layers\": list(range(4, 15, 2)),\n",
    "    \"save_path\": \"gemma_sae_cache\",\n",
    "    \"sae_class\": JumpReLUSAE,\n",
    "    \"model_name_short\": \"gemma\",\n",
    "    \"unlearn\": {\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"k_features\": 10,\n",
    "        \"alpha\": 5,\n",
    "    },\n",
    "    \"neuronpedia_id\": \"gemma-2-2b\",\n",
    "    \"neuronpedia_source_suffix\": \"-gemmascope-res-16k\",\n",
    "    \"layer_to_plot\": 10\n",
    "}\n",
    "\n",
    "LLAMA_CONFIG = {\n",
    "    \"sae_layers\": list(range(4, 30, 2)),\n",
    "    \"save_path\": \"llama_sae_cache\",\n",
    "    \"sae_class\": TopkSae,\n",
    "    \"model_name_short\": \"llama\",\n",
    "    \"unlearn\": {\n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"k_features\": 10,\n",
    "        \"alpha\": 30,\n",
    "    },\n",
    "    \"neuronpedia_id\": \"llama3.1-8b\",\n",
    "    \"neuronpedia_source_suffix\": \"-llamascope-res-32k\",\n",
    "    \"layer_to_plot\": 20\n",
    "}\n",
    "\n",
    "CONFIG = GEMMA_CONFIG if is_gemma else LLAMA_CONFIG\n",
    "\n",
    "SAE_LAYERS = CONFIG[\"sae_layers\"]\n",
    "\n",
    "print(f\"Using model: {MODEL_CARD}\")\n",
    "print(f\"Operating on layers: {SAE_LAYERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c119775",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = CONFIG[\"save_path\"]\n",
    "SAE_CLASS = CONFIG[\"sae_class\"]\n",
    "\n",
    "print(f\"Checking/Downloading SAEs to {save_path}...\")\n",
    "for layer in SAE_LAYERS:\n",
    "    layer_path = os.path.join(save_path, f\"layer_{layer}\")\n",
    "    if not os.path.exists(layer_path):\n",
    "        print(f\"Downloading SAE for layer {layer}...\")\n",
    "        SAE_CLASS.download_and_save(layer=layer, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CRISPConfig(\n",
    "    layers=SAE_LAYERS, \n",
    "    model_name=CONFIG[\"model_name_short\"], \n",
    "    bf16=True\n",
    ")\n",
    "crisp = CRISP(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d192a",
   "metadata": {},
   "source": [
    "## 3. Load Data\n",
    "We load the forget dataset (Harry Potter text) and a retain dataset (general book text) to help the model distinguish between what to remove and what to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab2df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Harry Potter text to unlearn and retain data\n",
    "data_config = HPDataConfig(n_examples=2500)\n",
    "\n",
    "data = load_hp_data(\n",
    "    n_examples=data_config.n_examples,\n",
    "    benign=data_config.retain_type,\n",
    "    max_len=data_config.max_length\n",
    ")\n",
    "print(f\"Loaded {len(data['forget'])} HP examples and {len(data['retain'])} retain examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f2d8f",
   "metadata": {},
   "source": [
    "## 4. Identify Salient Features\n",
    "CRISP uses SAEs to identify features that are highly active on the forget data but not on the retain data. These salient features represent the specific knowledge we want to unlearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process texts to identify Harry Potter-specific features\n",
    "print(\"Processing features (this may take a moment)...\")\n",
    "crisp.process_multi_texts_batch(\n",
    "    text_target=data['forget'],\n",
    "    text_benign=data['retain'],\n",
    "    data_config=data_config,\n",
    "    batch_size=8\n",
    ")\n",
    "print(\"Feature processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b1ac09",
   "metadata": {},
   "source": [
    "## 5. Unlearn\n",
    "We apply the unlearning process. This involves fine-tuning the model (using LoRA) to suppress the identified salient features while maintaining performance on general tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597cc2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "crisp.unload_lora()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "uconfig = UnlearnConfig(\n",
    "    learning_rate=CONFIG[\"unlearn\"][\"learning_rate\"],\n",
    "    k_features=CONFIG[\"unlearn\"][\"k_features\"],\n",
    "    alpha=CONFIG[\"unlearn\"][\"alpha\"],\n",
    "    beta=0.99,\n",
    "    gamma=0.01,\n",
    "    batch_size=4,\n",
    "    lora_rank=4,\n",
    "    data_type=\"hp\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Starting unlearning process...\")\n",
    "unlearn_lora(crisp, text_target=data['forget'], text_benign=data['retain'], config=uconfig, data_config=data_config)\n",
    "print(\"Unlearning complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*50)\n",
    "print(\"Original Model\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "with crisp.model.disable_adapter():\n",
    "    print(\"Evaluating original Harry Potter accuracy...\")\n",
    "    original_hp_acc = get_mcq_accuracy(crisp, type=\"hp\")\n",
    "\n",
    "    print(\"Generating Harry Potter evaluation text of origina model...\")\n",
    "    genenrate_hp_eval_text(crisp)\n",
    "\n",
    "    print(f\"Evaluating original MMLU accuracy...\")\n",
    "    original_mmlu_acc = get_mcq_accuracy(crisp, type=\"mmlu\")\n",
    "\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"After Unlearning\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Evaluating Harry Potter accuracy after unlearning...\")\n",
    "hp_acc_after = get_mcq_accuracy(crisp, type=\"hp\")\n",
    "print(f\"HP Accuracy after unlearning: {hp_acc_after:.2%} vs original {original_hp_acc:.2%}\")\n",
    "\n",
    "print(\"Generating Harry Potter evaluation text after unlearning...\")\n",
    "genenrate_hp_eval_text(crisp)\n",
    "\n",
    "print(\"Evaluating MMLU accuracy after unlearning...\")\n",
    "after_acc = get_mcq_accuracy(crisp, type=\"mmlu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76464ea1",
   "metadata": {},
   "source": [
    "## 6. Analysis and Visualization\n",
    "We visualize the features to see which ones were identified as salient. We also inspect the top features using Neuronpedia to understand what concepts they represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize features for one of the layers\n",
    "layer_to_plot = CONFIG[\"layer_to_plot\"]\n",
    "\n",
    "cached_features = load_cached_features(layer_to_plot, data_config, model_name=MODEL_CARD)\n",
    "layer_features = LayerFeatures(cached_features)\n",
    "\n",
    "print(f\"Loaded {len(layer_features.features)} features for layer {layer_to_plot}\")\n",
    "\n",
    "plot_features_scatter(\n",
    "    layer_features=layer_features,\n",
    "    k_features=5,\n",
    "    top_percentile=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69232799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the most salient feature using Neuronpedia\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "model_id = CONFIG[\"neuronpedia_id\"]\n",
    "\n",
    "# Find feature with highest target_acts_relative\n",
    "best_feature = max(layer_features.topk_filtered(5), key=lambda f: f.target_acts_relative)\n",
    "feature_index = best_feature.index\n",
    "\n",
    "print(f\"Inspecting Feature {feature_index} from Layer {layer_to_plot}...\")\n",
    "\n",
    "feature_data = get_feature_tokens(model_id, layer_to_plot, feature_index, top_k=5)\n",
    "\n",
    "if feature_data:\n",
    "    source = f\"{layer_to_plot}{CONFIG['neuronpedia_source_suffix']}\"\n",
    "        \n",
    "    neuronpedia_url = f\"https://www.neuronpedia.org/{model_id}/{source}/{feature_index}\"\n",
    "\n",
    "    # Create HTML content\n",
    "    tokens_html = ' '.join([f'<span style=\"background-color: #e1ecf4; color: #2c5282; padding: 2px 8px; border-radius: 4px; margin-right: 5px; display: inline-block; border: 1px solid #b3d4fc;\">{token}</span>' for token in feature_data['pos_str']])\n",
    "    \n",
    "    description = feature_data['explanations'][0]['description'] if feature_data.get('explanations') else \"No description available\"\n",
    "\n",
    "    html_content = f\"\"\"\n",
    "    <div style=\"border: 1px solid #e0e0e0; padding: 20px; border-radius: 8px; background-color: #ffffff; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif; box-shadow: 0 2px 4px rgba(0,0,0,0.05); max-width: 600px;\">\n",
    "        <div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px; border-bottom: 1px solid #eee; padding-bottom: 10px;\">\n",
    "            <h3 style=\"margin: 0; color: #333; font-size: 1.2em;\">Feature {feature_index}</h3>\n",
    "            <span style=\"background-color: #f0f0f0; color: #666; padding: 2px 8px; border-radius: 12px; font-size: 0.8em;\">Layer {layer_to_plot}</span>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"margin-bottom: 20px;\">\n",
    "            <div style=\"text-transform: uppercase; font-size: 0.75em; color: #888; margin-bottom: 5px; letter-spacing: 0.5px;\">Auto Description</div>\n",
    "            <div style=\"font-size: 1.1em; color: #1a1a1a; line-height: 1.4;\">{description}</div>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"margin-bottom: 20px;\">\n",
    "            <div style=\"text-transform: uppercase; font-size: 0.75em; color: #888; margin-bottom: 8px; letter-spacing: 0.5px;\">Top Tokens (Logit Lens)</div>\n",
    "            <div style=\"display: flex; flex-wrap: wrap; gap: 5px;\">\n",
    "                {tokens_html}\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"text-align: right;\">\n",
    "            <a href=\"{neuronpedia_url}\" target=\"_blank\" style=\"color: #0969da; text-decoration: none; font-size: 0.9em; font-weight: 500;\">View on Neuronpedia &rarr;</a>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crisp_env_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
